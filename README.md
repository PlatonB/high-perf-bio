# Синопсис.
## Преимущества.
- Высокая скорость работы:
    - вплоть до 8 процессов одновременно;
    - в основе - известная своей производительностью СУБД _MongoDB_.
- Простота запуска любого компонента:
    - одна команда - обработка всех коллекций базы;
    - не более двух обязательных аргументов.
- Наглядность:
    - вывод примерной структуры интересующей БД.
- Полностью автоматическое чтение и создание VCF и BED.
- Всегда бесплатная [техподдержка](https://github.com/PlatonB/high-perf-bio/issues).

# Перед началом работы.
## Если кратко.
1. Разрешите [зависимости](https://github.com/PlatonB/high-perf-bio#установка-сторонних-компонентов).
2. Скачайте архив с инструментарием:
```
Clone or download
```
(зелёная кнопка наверху страницы репозитория).

3. Распакуйте его в любую папку.
4. Освойте [запуск программ из терминала](https://github.com/PlatonB/ngs-pipelines#преодолеваем-страх-командной-строки-linux).

## Установка сторонних компонентов.
### MongoDB.
Советую вначале ознакомиться с [основами работы в линуксовым терминале](https://github.com/PlatonB/ngs-pipelines#преодолеваем-страх-командной-строки-linux). Впрочем, если совсем лень, можете просто копировать, вставлять и запускать приведённые ниже команды. После установки настоятельно рекомендую перезагрузиться.

#### Ubuntu Linux.
([elementary OS](https://elementary.io/ru/)/KDE neon/Linux Mint)

Подключение официального репозитория _MongoDB_.
```
wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add -
```
```
echo "deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.2.list
```

Обновление индекса пакетов ОС.
```
sudo apt update
```

Собственно, установка _MongoDB_.
```
sudo apt install -y mongodb-org
```

Перманентный запуск _MongoDB_. Лучше так сделать, если планируете использовать _high-perf-bio_ и [_ld-tools_](https://github.com/PlatonB/ld-tools) часто.
```
systemctl enable mongod.service
```

Если вам не нужно эксплуатировать _MongoDB_-решения каждый день, то рекомендую команду, активирующую _MongoDB_ до ближайшей перезагрузки.
```
sudo service mongod start
```

#### Fedora Linux.
TBD.

### PyMongo.
Установка с помощью _pip_:
```
pip3 install pymongo
```

Установка с помощью [_Conda_](https://github.com/PlatonB/ngs-pipelines#установка-conda):
```
conda install pymongo
```

### Примечание по поводу Windows.
Теоретически, после установки _MongoDB_ и whl-пакета _PyMongo_, программа должна работать. Но у меня сейчас _Windows_ нет, и я пока не проверял. Надеюсь, кто-нибудь поделится опытом в [Issues](https://github.com/PlatonB/high-perf-bio/issues).

# Тьюториал.
Компоненты _high-perf-bio_ управляются исключительно командами. Если вы имели дело только с графическими интерфейсами, можете почитать [мой материал о командной строке](https://github.com/PlatonB/ngs-pipelines#преодолеваем-страх-командной-строки-linux). Ничего сложного там нет, а если что, [обращайтесь](https://github.com/PlatonB/high-perf-bio/issues), я помогу.

Чтобы не прописывать каждый раз путь к тому или иному компоненту, перейдём в основную папку инструментария.
```
cd $HOME/Биоинформатика/high-perf-bio-master
```
Примечание: корректируйте приведённые в примерах пути в зависимости от реального расположения ваших папок или файлов.

Для удобства можете вывести имена всех программ проекта _high-perf-bio_.
```
ls
```

Каждый инструмент содержит подробную справку. Пока с ней не ознакомились, реальные задачи не запускайте.
```
python3 create_db.py -h
```
```
python3 annotator.py -h
```
и т.д..

В папке high-perf-bio-master уже есть небольшие примеры данных. Но в качестве материала для базы лучше скачать что-то серьёзное, например, VCF-таблицу [распространённых SNP](ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF/common_all_20180418.vcf.gz).

Поскольку формат этого файла - VCF, программа создания БД сама отбросит технические строки, сконвертирует ячейки определённых столбцов в BSON-структуры и проиндексирует поля с хромосомами, позициями и rsIDs. Файл - один, значит, распараллелить загрузку не удастся. Таким образом, команда может получиться весьма минималистичной.
```
python3 create_db.py -S $HOME/Биоинформатика/dbSNP_common
```

Есть вероятность возникновения двух проблем: вы забыли, как называется БД и из чего она состоит. В таких ситуациях перед запуском любого парсера требуется получить представление о парсимой БД. Для начала найдите её имя в списке всех имён.
```
python3 print_db_info.py
```

Затем выведите имена коллекций, индексов и другие первостепенные характеристики конкретной базы.
```
python3 print_db_info.py -d dbSNP_common
```

Теперь мы многое знаем о БД и можем, к примеру, осуществить по ней запрос. Допустим, отберём снипы интервала chr14:105746998-105803861, упомянутого в статье "Локусы влияющие на экспрессию антигенов HLA в участке 14-й хромосомы, ассоциированном с развитием рассеянного склероза, и функции расположенных в них генов" (П.А. Быкадоров и др.).
```
python3 make_request.py -D dbSNP_common -T $HOME/Биоинформатика/результаты -q '{"#CHROM": "14", "POS": {"$gt": 105746998, "$lt": 105803861}}'
```

Давайте найдём характеристики SNPs папки high-perf-bio-master/test_data/TSV. С расположением rsID-столбца повезло - он первый. С базой dbSNP_common тоже всё ок - есть поле ID. Значит, обойдёмся минимумом аргументов: путь к игрушечным таблицам, имя базы и исключение табличной шапки. Результаты в этом примере попадут в исходную папку.
```
python3 annotator.py -S $HOME/Биоинформатика/high-perf-bio-master/test_data/TSV -D dbSNP_common -m 1
```

Интересно, а есть на свете снипы, являющиеся eQTL сразу во всех тканях? Сейчас посмотрим. Скачаем [таблицы значимых пар eQTL-eGene](https://storage.googleapis.com/gtex_analysis_v8/single_tissue_qtl_data/GTEx_Analysis_v8_eQTL.tar). Нам понадобятся только \*.egenes.txt.gz-файлы. \*.signif_variant_gene_pairs.txt.gz-файлы можете быстро удалить каким-нибудь продвинутым файлменеджером (типа _Double Commander_) или этим незамысловатым Python-скриптом:
```
import os
gtex_dir_path = 'путь_к_папке/GTEx_Analysis_v8_eQTL'
for gtex_file_name in os.listdir(gtex_dir_path):
        if gtex_file_name.find('signif') != -1:
                os.remove(os.path.join(gtex_dir_path, gtex_file_name))
```

Зальём оставшиеся таблицы в базу. Дадим базе легко воспринимаемое имя, проиндексируем коллекции по rsID-столбцу. Коллекций - несколько десятков, поэтому лично я предпочёл бы распараллелить размещение и индексацию на 8 процессов.
```
python3 create_db.py -S $HOME/Биоинформатика/GTEx_Analysis_v8_eQTL -d GTEx -i rs_id_dbSNP151_GRCh38p7 -p 8
```

Что такое левые/правые коллекции и глубина, подробно рассказано в справке _intersect_subtract_ - здесь я на этом останавливаться не буду. Указываем в явном виде одну левую коллекцию. Любую. Правыми коллекциями для решения задачи надо сделать все остальные, но перечислять их не нужно - для программы такой сценарий предусмотрен по дефолту. То, что нам нужно пересекать, а не вычитать, опять же, явно прописывать не обязательно. А вот имя пересекаемого поля программе от нас потребуется, ведь коллекции делались по таблицам небиоинформатического формата, а в этом случае применимы не все удобные умолчания. eQTL нам общие для всех тканей надо найти? Значит, пишем глубину, равную количеству всех коллекций минус 1 (вычли одну левую).
```
python3 intersect_subtract.py -D GTEx -T $HOME/Биоинформатика/результаты -l Adipose_Subcutaneous.v8.egenes.txt -f rs_id_dbSNP151_GRCh38p7 -d 48
```

Вездесущие eQTL обнаружились, и их 63 штуки. А сколько будет SNPs, влияющих на экспрессию генов только в крови и больше нигде? Это решается вычитанием.
```
python3 intersect_subtract.py -D GTEx -T $HOME/Биоинформатика/результаты -l Whole_Blood.v8.egenes.txt -f rs_id_dbSNP151_GRCh38p7 -a subtract -d 48
```

Таких уникальных снипов аж около половины - 10963 из 20315 всех кровяных.

Мы сейчас работали с полными наборами пар снипов-генов. Стоит заметить, что не во всех из них встречаются настоящие eGenes. Чтобы таковые получить, надо произвести отбор по порогу q-value<=0.05. Индекс rsID-поля для этого точно не потребуется, но заметный прирост скорости дал бы индекс поля с q-value. Узнаём имена удаляемого индекса и индексируемого поля, после чего готовим все коллекции к поиску eGenes.
```
python3 print_db_info.py -d GTEx
```
```
python3 reindex_db.py -D GTEx -r rs_id_dbSNP151_GRCh38p7_1 -a qval -p 8
```

Теперь фильтруем.
```
python3 make_request.py -D GTEx -T $HOME/Биоинформатика/результаты -q '{"qval": {"$lte": Decimal128("0.05")}}' -p 8
```

Полученные результаты можно отправить в новую базу, с чем вы уже точно справитесь самостоятельно.

# Полезные советы.
## Метастроки.
У части тулзов _high_perf_bio_ есть опция --meta-lines-quan/-m. Она даёт программе знать, сколько строк в начале файла не нужно никак трогать. Эти строки содержат т.н. метаинформацию, которая посвящает исследователя в различные особенности файла. Программам же они, как правило, только мешают. VCF - формат довольно строгий, и там метастроки чётко обозначены символами ##, что даёт возможность скипать их автоматически. Для остальных форматов требуется ручное указание количества игнорируемых строк. Как это количество узнать? Если файл - маленький, просто откройте его в обычном блокноте. В хороших блокнотах, как, например, [elementary OS](https://elementary.io/ru/) Code, есть нумерация строк, что облегчает задачу. Если же большой, то так сделать не получится - в лучшем случае вылезет ошибка, в худшем - осложните себе работу зависанием. Вас раздражает командная строка? Можете считывать первые строки сжатого файла скриптом-предпросмотрщиком из моего репозитория [bioinformatic-python-scripts](https://github.com/PlatonB/bioinformatic-python-scripts). Уже привыкли к эмулятору терминала? Тогда юзайте командную утилиту _zless_.
```
zless -N $HOME/Биоинформатика/dbSNP_common/00-common_all.vcf.gz
```

Скроллить можно колесом мыши или двумя пальцами вверх-вниз по тачпаду. Закрыть предпросмотр: `q`.

## Спецсимволы.
В ту или иную команду могут закрасться зарезервированные символы. Командная оболочка, на них наткнувшись, не сможет обработать вашу команду как единое целое. Я, к примеру, при тестировании _high_perf_bio_ получил ошибку из-за решётки в начале имени хромосомного поля.
```
python3 create_db.py -S $HOME/Биоинформатика/dbSNP_common -i #CHROM,POS,ID
```
```
create_db.py: error: argument -i/--ind-col-names: expected one argument
```

Из-за наличия решётки интерпретатор подумал, что CHROM,POS,ID - комментарий, а не перечисление индексируемых полей. Получилось, что аргумент -i, строго требующий значения, остался без такового. Надо было просто взять набор имён полей в одинарные кавычки (заэкранировать).
```
python3 create_db.py -S $HOME/Биоинформатика/dbSNP_common -i '#CHROM,POS,ID'
```

А знаете, почему программы _high_perf_bio_ заставляют перечислять что-либо через запятую без привычного нам по естественным языкам пробела? Не подумайте, что из вредности:). Пробел считается границей между аргументами. Т.е., при использовании запятых с пробелом каждый следующий элемент воспринимался бы шеллом в качестве нового аргумента.
```
python3 create_db.py -S $HOME/Биоинформатика/high-perf-bio-master/test_data/TSV -i SYMBOL, AF
```
```
create_db.py: error: unrecognized arguments: AF
```

Требование перечислять без пробела я ввёл, чтобы избавить вас от необходимости экранирования. Правильное оформление последней команды не подразумевает обязательного наличия надоедливых кавычек.
```
python3 create_db.py -S $HOME/Биоинформатика/high-perf-bio-master/test_data/TSV -i SYMBOL,AF
```
